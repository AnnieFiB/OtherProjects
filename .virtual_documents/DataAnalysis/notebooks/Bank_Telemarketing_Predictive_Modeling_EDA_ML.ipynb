











import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from autoviz import AutoViz_Class
import importlib
import joblib

import os
import sys
sys.path.append("../scripts")
import data_processing_framework as dpf
import ml_pipeline_utils as mlpu

import warnings
warnings.filterwarnings('ignore')


# Load data
train = pd.read_csv('datasets/bank_train.csv')
test = pd.read_csv('datasets/bank_test.csv')

# Display structure
print(train.info())
#print("\nMissing values:\n", train.isnull().sum())


train.head()





train.describe()





# Autoviz display
%matplotlib inline
AV = AutoViz_Class()
dfte = AV.AutoViz(filename="", sep=',', depVar='y', dfte=train, header=0, verbose=2, lowess=False,
               chart_format='svg',max_rows_analyzed=150000,max_cols_analyzed=30, save_plot_dir="reports_html")


#autoviz report to html
dpf.generate_autoviz_html_report(folder_name="reports_html/y", output_filename="bank_telemark_eda_report.html")








# plot outliers across all numeric columns using IQR
dpf.plot_outliers_boxplot(train, title="Train_set Outliers")








# Check for full-row duplicates 
duplicates = train.duplicated().sum()
print(f" Duplicate rows : {duplicates}")


# Apply Winsorization to both train and test sets
train = dpf.winsorize_dataframe(train)
test = dpf.winsorize_dataframe(test)
dpf.plot_outliers_boxplot(train, title="Train_set Outliers")
dpf.plot_outliers_boxplot(test, title="Test_set Outliers")


# Strip whitespace from all object columns
for col in train.select_dtypes(include='object').columns:
    train[col] = train[col].str.strip().str.lower()  # convert to lowercase for consistency


# Check unique values
for col in train.select_dtypes(include='object').columns:
    print(f"{col}: {train[col].unique()}")








# feature importance
importance_df = mlpu.compute_combined_feature_importance(train, target_column='y', top_n=15, plot=True)
#print(importance_df)


# Encode categorical and boolean variables (label encoding and one-hot encoding).
X_train, y_train = mlpu.prepare_features(
    train,
    target_column='y',
    drop_columns=[]
)

X_test, y_test = mlpu.prepare_features(
    test,
    target_column='y',
    drop_columns=[]
)


# scale for numerical attributes 
X_train_scaled, X_test_scaled, pipeline = mlpu.scale_train_test(X_train, X_test)


y_train.value_counts()


y_test.value_counts()





# Balance the training set
X_train_resampled, y_train_resampled = mlpu.balance_classes_smote(X_train, y_train)
print(y_train_resampled.value_counts())





# Train and evaluate models
selected = ["Dummy","Logistic Regression", "Naive Bayes", "Random Forest","Decision Tree","Neural Network"]
results, trained_models =  mlpu.train_and_evaluate_models(X_train_resampled, y_train_resampled, selected_models=selected)



# Observe Metrics
summary_df = mlpu.results_to_dataframe(results)
summary_df





# plt model metric
mlpu.plot_model_evaluations(trained_models, X_test, y_test)














#Tune selected models and save best model
models_and_params = mlpu.load_models_and_params() # Load all models and params

# Pick specific models to tune
selected = ["Naive Bayes", "Random Forest", "Decision Tree"]
selected_models_and_params = {
    name: models_and_params[name] for name in selected
    }


best_model, best_name, best_scores = mlpu.tune_and_select_best_model(
    X_train, y_train,
    models_and_params=selected_models_and_params,
    save_path="best_telemarketing_model.pkl"
)





# Load the best saved model
best_model = joblib.load("best_telemarketing_model.pkl")
# Use the dynamic name of the best model (assume best_name is available)
tn, fp, fn, tp = sum(results[best_name]['confusion_matrix'], [])

# Optional: Print for confirmation
print(f"âœ… Best Model: {best_name}")
print(f"""
**Actionable Insights**:
- Target customers predicted as 'subscribe' (TP): {tp} (high conversion probability)
- Avoid customers predicted as 'not subscribe' (TN): {tn} (reduces unnecessary calls)
- Investigate false negatives (FN): {fn} (missed opportunities)
- Reduce false positives (FP): {fp} (cost savings)
""")









