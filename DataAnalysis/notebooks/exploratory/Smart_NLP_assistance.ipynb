{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee3a9412-8b11-487b-8c70-bb7ba654b8d1",
   "metadata": {},
   "source": [
    "# Smart NLP Assistant for General Reviews & Banking Support"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5246c4-f6bd-4016-a579-680b10635758",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Project Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ba9750-2280-4570-b3e2-4fcb1cfa7efb",
   "metadata": {},
   "source": [
    "This project combines two powerful NLP tools into one assistant:\n",
    "- A **Multilingual Sentiment Analyzer** for general product or service reviews.\n",
    "- An **AutoReply Generator** for banking-related customer support emails.\n",
    "\n",
    "The system supports multiple languages, detects user intent, translates input/output, classifies messages, and either performs sentiment analysis or generates a smart reply.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df57157-62a9-4519-bcc3-f790ce3f2af7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8646d084-3593-4e71-8f0e-e9a885065431",
   "metadata": {},
   "source": [
    "- Build a multilingual NLP assistant that:\n",
    "  - Detects input language\n",
    "  - Translates input to English for model processing\n",
    "  - Performs sentiment analysis for general reviews (e.g., products, services, apps)\n",
    "  - Classifies and replies to banking-related support messages\n",
    "  - Translates the result back to the original language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a05336-e2bb-4fe7-ae6b-2fb880e94e77",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Real-Life Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0648e51-c690-4a7a-b5c6-42a802f09cf9",
   "metadata": {},
   "source": [
    "- **Customer Reviews**: Analyze reviews from e-commerce, app stores, or service platforms to gauge customer sentiment across regions.\n",
    "- **Customer Support**: Automatically respond to common banking-related support emails in the customerâ€™s native language.\n",
    "- **Multilingual Expansion**: Serve users from different countries without manually translating or localizing every message.\n",
    "- **Insight Extraction**: Quickly identify negative feedback for escalation or improvement efforts in any domain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89793817-dc65-4235-ab3a-1a5c30f7da0d",
   "metadata": {},
   "source": [
    "## Tech Stack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992c8282-4db8-4f1b-9554-7c34271ab682",
   "metadata": {},
   "source": [
    "- **Python**\n",
    "- **Hugging Face Transformers**\n",
    "  - Translation: `Helsinki-NLP/opus-mt-{lang}-en`\n",
    "  - Sentiment: `distilbert-base-uncased-finetuned-sst-2-english`\n",
    "- **Langdetect**: automatic language identification\n",
    "- **Matplotlib / Pandas**: data handling and visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0641ff-8177-4da5-be4f-16f85b23e107",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Project Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46ad9e7-7a07-4f60-ba30-3ed28246719f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "1. **Input**: User message (review or support request)\n",
    "2. **Language Detection**\n",
    "3. **Translation to English**\n",
    "4. **Intent Selection**:\n",
    "   - Review â†’ Sentiment Analysis\n",
    "   - Support Email â†’ Classification + Reply\n",
    "5. **Output**: Sentiment or AutoReply (in original language with English reference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc62192a-2fba-4060-85b5-cc28c7ad1a66",
   "metadata": {},
   "source": [
    "## Load dependencies and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "326f85e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch  # Add this with other imports\n",
    "import importlib\n",
    "\n",
    "import os\n",
    "import sys\n",
    "scripts_path = os.path.abspath(os.path.join(os.getcwd(), '..', 'scripts'))\n",
    "sys.path.append(scripts_path) # Add 'scripts' directory to sys.path\n",
    "import smart_nlp_assistant as snlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98b7d686-2d95-4ab0-b64e-18f1cdf922c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'smart_nlp_assistant' from 'D:\\\\Portfolio\\\\my_projects\\\\DataAnalysis\\\\scripts\\\\smart_nlp_assistant.py'>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(snlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bd1e48-1a69-442a-a353-7d6097bef589",
   "metadata": {},
   "source": [
    "### Initialize models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "014788b8-0920-49c1-b80c-965c1fbe646c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Loading models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Models loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Initialize models\n",
    "sentiment_model = snlp.initialize_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4923dc51-76d0-4491-a52a-3064d7a45c3f",
   "metadata": {},
   "source": [
    "## Get user preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e17dad0c-89a4-42d0-b75b-b1aeaf779e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smart NLP Assistant - Select Mode:\n",
      "1. Review Sentiment Analysis\n",
      "2. Banking Support Auto-Reply\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter choice (1 or 2):  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Select Input Method:\n",
      "1. Enter text directly\n",
      "2. Process CSV file\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter choice (1 or 2):  1\n"
     ]
    }
   ],
   "source": [
    "# Get user preferences\n",
    "mode = snlp.get_user_mode()\n",
    "input_method = snlp.get_input_method()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326d7102-5f3b-48e3-9cda-eb1798b8c766",
   "metadata": {},
   "source": [
    "## Process based on input method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1c875ce0-cf91-4814-a38e-a90760f2ec64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âŒ An error occurred during processing: name 'get_text_input' is not defined\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    if input_method == \"text\":\n",
    "        user_text = get_text_input()\n",
    "        results = process_single_text(user_text, mode, sentiment_model)\n",
    "    else:\n",
    "        file_path, text_column = get_csv_input()\n",
    "        results = process_csv_file(file_path, text_column, mode, sentiment_model)\n",
    "        \n",
    "    show_visualizations(results, mode)\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"\\nâŒ Error: {str(e)}\")\n",
    "    print(\"Please install missing dependencies and restart your kernel\")\n",
    "    if \"sentencepiece\" in str(e):\n",
    "        print(\"Try running: !pip install sentencepiece\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ An error occurred during processing: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5186b411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your text:  No puedo acceder a mi cuenta bancaria desde ayer.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nMarianTokenizer requires the SentencePiece library but it was not found in your environment. Checkout the instructions on the\ninstallation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\nthat match your environment. Please note that you may need to restart your runtime after installation.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m      5\u001b[0m     user_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEnter your text: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43msnlp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msentiment_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msentiment_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(result)\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# Display results\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Portfolio\\my_projects\\DataAnalysis\\scripts\\smart_nlp_assistant.py:147\u001b[0m, in \u001b[0;36mprocess_input\u001b[1;34m(text, mode, sentiment_model)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Main function to process input text based on selected mode\"\"\"\u001b[39;00m\n\u001b[0;32m    146\u001b[0m lang \u001b[38;5;241m=\u001b[39m detect_language(text)\n\u001b[1;32m--> 147\u001b[0m translated \u001b[38;5;241m=\u001b[39m \u001b[43mtranslate_to_english\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlang\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreview\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    150\u001b[0m     label, score \u001b[38;5;241m=\u001b[39m analyze_sentiment(translated, sentiment_model)\n",
      "File \u001b[1;32mD:\\Portfolio\\my_projects\\DataAnalysis\\scripts\\smart_nlp_assistant.py:47\u001b[0m, in \u001b[0;36mtranslate_to_english\u001b[1;34m(text, lang)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lang \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m lang \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m LANG_CODE_MAP:\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m text\n\u001b[1;32m---> 47\u001b[0m model, tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mload_translation_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mLANG_CODE_MAP\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlang\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m tokens \u001b[38;5;241m=\u001b[39m tokenizer([text], return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     49\u001b[0m translated \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtokens)\n",
      "File \u001b[1;32mD:\\Portfolio\\my_projects\\DataAnalysis\\scripts\\smart_nlp_assistant.py:39\u001b[0m, in \u001b[0;36mload_translation_model\u001b[1;34m(code)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load translation model for given language code\"\"\"\u001b[39;00m\n\u001b[0;32m     38\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHelsinki-NLP/opus-mt-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 39\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mMarianTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m(model_name)\n\u001b[0;32m     40\u001b[0m model \u001b[38;5;241m=\u001b[39m MarianMTModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model, tokenizer\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\utils\\import_utils.py:1840\u001b[0m, in \u001b[0;36mDummyObject.__getattribute__\u001b[1;34m(cls, key)\u001b[0m\n\u001b[0;32m   1838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_from_config\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1839\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(key)\n\u001b[1;32m-> 1840\u001b[0m \u001b[43mrequires_backends\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backends\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\utils\\import_utils.py:1828\u001b[0m, in \u001b[0;36mrequires_backends\u001b[1;34m(obj, backends)\u001b[0m\n\u001b[0;32m   1826\u001b[0m failed \u001b[38;5;241m=\u001b[39m [msg\u001b[38;5;241m.\u001b[39mformat(name) \u001b[38;5;28;01mfor\u001b[39;00m available, msg \u001b[38;5;129;01min\u001b[39;00m checks \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m available()]\n\u001b[0;32m   1827\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m failed:\n\u001b[1;32m-> 1828\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(failed))\n",
      "\u001b[1;31mImportError\u001b[0m: \nMarianTokenizer requires the SentencePiece library but it was not found in your environment. Checkout the instructions on the\ninstallation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\nthat match your environment. Please note that you may need to restart your runtime after installation.\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Process Input\n",
    "results = []\n",
    "\n",
    "if input_method == \"text\":\n",
    "    user_text = input(\"\\nEnter your text: \")\n",
    "    result = snlp.process_input(user_text, mode=mode, sentiment_model=sentiment_model)\n",
    "    results.append(result)\n",
    "    \n",
    "    # Display results\n",
    "    print(\"\\nResults:\")\n",
    "    for key, value in result.items():\n",
    "        print(f\"{key.title().replace('_', ' ')}: {value}\")\n",
    "else:\n",
    "    file_path = input(\"\\nEnter CSV file path: \")\n",
    "    texts = load_text_from_csv(file_path)\n",
    "    \n",
    "    if not texts:\n",
    "        print(\"No valid text data found in the CSV file\")\n",
    "    else:\n",
    "        print(f\"\\nProcessing {len(texts)} entries...\")\n",
    "        for text in texts:\n",
    "            results.append(process_input(text, mode=mode, sentiment_model=sentiment_model))\n",
    "        \n",
    "        # Save and show results\n",
    "        output_path = save_results_to_csv(results)\n",
    "        print(f\"\\nâœ… Results saved to {output_path}\")\n",
    "        \n",
    "        # Show sample results\n",
    "        print(\"\\nSample Results:\")\n",
    "        print(pd.DataFrame(results).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a877ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Visualization\n",
    "if results:\n",
    "    if mode == \"review\":\n",
    "        plot_sentiment_distribution(results)\n",
    "    else:\n",
    "        plot_support_categories(results)\n",
    "else:\n",
    "    print(\"No results to visualize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2def7ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4466ee74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7cf74f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134f18b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603855e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "006bcfd7825e4c9b8f68d148a1d4561a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "0227c8a4fffe40de95b201f0010b1f06": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_bb9ca676fd414c4d9339eb1eaf30fd05",
       "style": "IPY_MODEL_b29b049cff0f470fad06fcca6e329da2",
       "value": "â€‡48.0/48.0â€‡[00:00&lt;00:00,â€‡2.42kB/s]"
      }
     },
     "0e289ca6abd24400997c614950c61139": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "2705c1f177174685a57f0fc76ce653f1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "2931d305865e4fb98081a1970a284d54": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "29829abd6fc944739b1ba034dfe05188": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_578a8cc1fd3044d39e2db573b5f68992",
        "IPY_MODEL_4636d75c83f848d78bb9803d55b3da44",
        "IPY_MODEL_0227c8a4fffe40de95b201f0010b1f06"
       ],
       "layout": "IPY_MODEL_a0a70d5b2f67423a9155789f9d4c2859"
      }
     },
     "3c063db1e7194a09ab93d9ef0eca13b8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "4636d75c83f848d78bb9803d55b3da44": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_8b3fb93a0c7648da82a197f1939e4ac0",
       "max": 48,
       "style": "IPY_MODEL_006bcfd7825e4c9b8f68d148a1d4561a",
       "value": 48
      }
     },
     "50039543abdb4a9dae7ae0ee1672107f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "578a8cc1fd3044d39e2db573b5f68992": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_db2aced78e7246c3b22dc2ad5d10b400",
       "style": "IPY_MODEL_ce9d11b7251b420fab0b0a0a46fdb187",
       "value": "tokenizer_config.json:â€‡100%"
      }
     },
     "6939d03ba4a142a38858dd89b9c1d56a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_2931d305865e4fb98081a1970a284d54",
       "max": 231508,
       "style": "IPY_MODEL_f5317e9b707b40368305fdfabddafc73",
       "value": 231508
      }
     },
     "73ae3e9f4f1a4d72a1a67bb7b20364cf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_3c063db1e7194a09ab93d9ef0eca13b8",
       "style": "IPY_MODEL_fd6cd7709cf14a5e8aa8f5095a4d2a97",
       "value": "vocab.txt:â€‡100%"
      }
     },
     "85a61423ceaf4991bfed8e94d647b7fc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_73ae3e9f4f1a4d72a1a67bb7b20364cf",
        "IPY_MODEL_6939d03ba4a142a38858dd89b9c1d56a",
        "IPY_MODEL_b4ef29d9c48a44c3bc3f73127b2a00b9"
       ],
       "layout": "IPY_MODEL_0e289ca6abd24400997c614950c61139"
      }
     },
     "8b3fb93a0c7648da82a197f1939e4ac0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a0a70d5b2f67423a9155789f9d4c2859": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "b29b049cff0f470fad06fcca6e329da2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b4ef29d9c48a44c3bc3f73127b2a00b9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_2705c1f177174685a57f0fc76ce653f1",
       "style": "IPY_MODEL_50039543abdb4a9dae7ae0ee1672107f",
       "value": "â€‡232k/232kâ€‡[00:00&lt;00:00,â€‡2.55MB/s]"
      }
     },
     "bb9ca676fd414c4d9339eb1eaf30fd05": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ce9d11b7251b420fab0b0a0a46fdb187": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "db2aced78e7246c3b22dc2ad5d10b400": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f5317e9b707b40368305fdfabddafc73": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "fd6cd7709cf14a5e8aa8f5095a4d2a97": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
