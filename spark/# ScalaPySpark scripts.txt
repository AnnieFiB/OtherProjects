--Spark (databricks: anniemona : https://dbc-edfc230d-57d2.cloud.databricks.com/?autoLogin=true&o=3502880284915803&dbx_source=organic)

python console :  pyspark quit()
Scala console : spark-shell :q
SQL console : spark-sql quit;

spark in cloud: https://github.com/databricks/Spark-The-Definitive-Guide
change the path in each chapter from /data to /databricks-datasets/definitive-guide/data

Spark has two fundamental sets of APIs: the low-level “unstructured” APIs, and the higher-level structured APIs

data structures are immutable, meaning they cannot be changed after they’re
created.

To “change” a DataFrame, you need to instruct Spark how you would like to
modify it to do what you want. These instructions are called transformations (narrow: 1to1, wide:1toN). 


--SCALA (spark-shell)
clear terminal: print("\u001b[2J\u001b[H")
spark.range() , spark.toDF(specify datatype)





















